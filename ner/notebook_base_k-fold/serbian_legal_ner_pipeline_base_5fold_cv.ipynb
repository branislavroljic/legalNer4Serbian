{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCxJ3lfIjTOm"
      },
      "source": [
        "# Serbian Legal Named Entity Recognition (NER) Pipeline - 5-Fold Cross-Validation\n",
        "\n",
        "This notebook implements 5-fold cross-validation for the Serbian Legal NER pipeline using the base BERT model (classla/bcms-bertic).\n",
        "\n",
        "## Key Features\n",
        "- **5-Fold Cross-Validation**: Robust evaluation across different data splits\n",
        "- **Base BERT Architecture**: Uses classla/bcms-bertic for token classification\n",
        "- **Sliding Window Tokenization**: Handles long sequences without truncation\n",
        "- **Comprehensive Metrics**: Precision, recall, F1-score, and accuracy tracking\n",
        "- **Statistical Analysis**: Mean and standard deviation across folds\n",
        "\n",
        "## Entity Types\n",
        "- **COURT**: Court institutions\n",
        "- **DECISION_DATE**: Dates of legal decisions\n",
        "- **CASE_NUMBER**: Case identifiers\n",
        "- **CRIMINAL_ACT**: Criminal acts/charges\n",
        "- **PROSECUTOR**: Prosecutor entities\n",
        "- **DEFENDANT**: Defendant entities\n",
        "- **JUDGE**: Judge names\n",
        "- **REGISTRAR**: Court registrar\n",
        "- **SANCTION**: Sanctions/penalties\n",
        "- **SANCTION_TYPE**: Type of sanction\n",
        "- **SANCTION_VALUE**: Value/duration of sanction\n",
        "- **PROVISION**: Legal provisions\n",
        "- **PROCEDURE_COSTS**: Legal procedure costs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGTyacPF64Th",
        "outputId": "5800a0bd-7d95-483f-97b0-0e1796cd1d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive (for Colab)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    USE_COLAB = True\n",
        "except ImportError:\n",
        "    USE_COLAB = False\n",
        "    print(\"Running locally\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxHG6Rs8jTOo"
      },
      "source": [
        "## 1. Environment Setup and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11kIuCNPjTOo",
        "outputId": "9efae440-a339-4ef3-c8a4-4f0f82a93ae6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (0.22.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m870.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=adfd8f0b362064cd1d5d59f943a6acddbaf34a377f3736bbd97513222d909e9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install transformers torch datasets tokenizers scikit-learn seqeval pandas numpy matplotlib seaborn tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3ig3oNUjTOo",
        "outputId": "a7db467d-3abe-433b-da82-494c5596b404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Setup complete:\n",
            "  PyTorch version: 2.8.0+cu126\n",
            "  CUDA available: False\n",
            "  Device: cpu\n",
            "  Random seed: 42\n"
          ]
        }
      ],
      "source": [
        "# Import shared modules\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the shared modules to path\n",
        "if USE_COLAB:\n",
        "    sys.path.append('/content/drive/MyDrive/NER_Master/ner/')\n",
        "else:\n",
        "    sys.path.append('../shared')\n",
        "\n",
        "import importlib\n",
        "import shared\n",
        "import shared.model_utils\n",
        "import shared.data_processing\n",
        "import shared.dataset\n",
        "import shared.evaluation\n",
        "import shared.config\n",
        "importlib.reload(shared.config)\n",
        "importlib.reload(shared.data_processing)\n",
        "importlib.reload(shared.dataset)\n",
        "importlib.reload(shared.model_utils)\n",
        "importlib.reload(shared.evaluation)\n",
        "importlib.reload(shared)\n",
        "\n",
        "# Import from shared modules\n",
        "from shared import (\n",
        "    # Configuration\n",
        "    ENTITY_TYPES, BIO_LABELS, DEFAULT_TRAINING_ARGS,\n",
        "    get_default_model_config, get_paths, setup_environment,\n",
        "\n",
        "    # Data processing\n",
        "    LabelStudioToBIOConverter, load_labelstudio_data,\n",
        "    analyze_labelstudio_data, validate_bio_examples,\n",
        "\n",
        "    # Dataset\n",
        "    NERDataset, split_dataset, tokenize_and_align_labels_with_sliding_window,\n",
        "    print_sequence_analysis, create_huggingface_datasets,\n",
        "\n",
        "    # Model utilities\n",
        "    load_model_and_tokenizer, create_training_arguments, create_trainer,\n",
        "    detailed_evaluation, save_model_info, setup_device_and_seed,\n",
        "\n",
        "    # Evaluation\n",
        "    generate_evaluation_report, plot_training_history, plot_entity_distribution\n",
        ")\n",
        "\n",
        "# Standard imports\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "import torch\n",
        "from transformers import DataCollatorForTokenClassification, AutoTokenizer\n",
        "\n",
        "# Setup device and random seed\n",
        "device = setup_device_and_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R56QtmR7fIY2"
      },
      "source": [
        "## 2. Configuration and Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i3CBXt2fIY3",
        "outputId": "79d380f2-ab8d-43bd-e64f-a10dc31d5a6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Environment setup (cloud):\n",
            "  ‚úÖ labelstudio_json: /content/drive/MyDrive/NER_Master/annotations.json\n",
            "  ‚úÖ judgments_dir: /content/drive/MyDrive/NER_Master/judgments\n",
            "  ‚úÖ labelstudio_files_dir: /content/drive/MyDrive/NER_Master/judgments\n",
            "  ‚úÖ mlm_data_dir: /content/drive/MyDrive/NER_Master/dapt-mlm\n",
            "  ‚úÖ models_dir: /content/drive/MyDrive/NER_Master/models\n",
            "  ‚úÖ logs_dir: /content/drive/MyDrive/NER_Master/logs\n",
            "  ‚úÖ results_dir: /content/drive/MyDrive/NER_Master/results\n",
            "üîß Configuration:\n",
            "  Model: classla/bcms-bertic\n",
            "  Output directory: /content/drive/MyDrive/NER_Master/models/bertic_base_5fold_cv\n",
            "  Entity types: 16\n",
            "  BIO labels: 33\n"
          ]
        }
      ],
      "source": [
        "# Setup environment and paths\n",
        "env_setup = setup_environment(use_local=not USE_COLAB, create_dirs=True)\n",
        "paths = env_setup['paths']\n",
        "\n",
        "# Model configuration\n",
        "MODEL_NAME = \"classla/bcms-bertic\"\n",
        "model_config = get_default_model_config()\n",
        "\n",
        "# Output directory\n",
        "OUTPUT_DIR = f\"{paths['models_dir']}/bertic_base_5fold_cv\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"üîß Configuration:\")\n",
        "print(f\"  Model: {MODEL_NAME}\")\n",
        "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
        "print(f\"  Entity types: {len(ENTITY_TYPES)}\")\n",
        "print(f\"  BIO labels: {len(BIO_LABELS)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVSwtVS1fIY3"
      },
      "source": [
        "## 3. Data Loading and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmq8DjhyfIY4",
        "outputId": "cb46d49e-47a8-4cde-84e3-7c1966c4b3b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded 225 annotated documents from /content/drive/MyDrive/NER_Master/annotations.json\n",
            "üìä Analysis Results:\n",
            "Total documents: 225\n",
            "Total annotations: 225\n",
            "Unique entity types: 14\n",
            "\n",
            "Entity distribution:\n",
            "  DEFENDANT: 1240\n",
            "  PROVISION_MATERIAL: 1177\n",
            "  CRIMINAL_ACT: 792\n",
            "  PROVISION_PROCEDURAL: 686\n",
            "  REGISTRAR: 460\n",
            "  COURT: 458\n",
            "  JUDGE: 451\n",
            "  PROSECUTOR: 395\n",
            "  DECISION_DATE: 359\n",
            "  SANCTION_TYPE: 248\n",
            "  SANCTION_VALUE: 241\n",
            "  VERDICT: 238\n",
            "  PROCEDURE_COSTS: 231\n",
            "  CASE_NUMBER: 225\n"
          ]
        }
      ],
      "source": [
        "# Load LabelStudio data\n",
        "labelstudio_data = load_labelstudio_data(paths['labelstudio_json'])\n",
        "\n",
        "# Analyze the data\n",
        "if labelstudio_data:\n",
        "    analysis = analyze_labelstudio_data(labelstudio_data)\n",
        "else:\n",
        "    print(\"‚ùå No data loaded. Please check your paths.\")\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGAyV4gQfIY4"
      },
      "source": [
        "## 4. Data Preprocessing and BIO Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOe5xEDnfIY5",
        "outputId": "961d278e-a28a-4a2d-e45e-4fdb1e5050ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Converted 225 examples to BIO format\n",
            "üìä BIO Validation Results:\n",
            "Total examples: 225\n",
            "Valid examples: 225\n",
            "Invalid examples: 0\n",
            "Empty examples: 0\n",
            "üìä Validation complete: 225 valid examples\n"
          ]
        }
      ],
      "source": [
        "# Convert LabelStudio data to BIO format\n",
        "converter = LabelStudioToBIOConverter(\n",
        "    judgments_dir=paths['judgments_dir'],\n",
        "    labelstudio_files_dir=paths.get('labelstudio_files_dir')\n",
        ")\n",
        "\n",
        "bio_examples = converter.convert_to_bio(labelstudio_data)\n",
        "print(f\"‚úÖ Converted {len(bio_examples)} examples to BIO format\")\n",
        "\n",
        "# Validate BIO examples\n",
        "valid_examples, stats = validate_bio_examples(bio_examples)\n",
        "print(f\"üìä Validation complete: {stats['valid_examples']} valid examples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HcyAbInfIY5"
      },
      "source": [
        "## 5. Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cX7CQA3fIY5",
        "outputId": "71eee81a-a8d0-49cf-b81c-7a49b58dc0c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Dataset statistics:\n",
            "  Number of unique labels: 29\n",
            "  Prepared examples: 225\n",
            "  Total tokens: 232475\n",
            "  Entity types found: 14\n"
          ]
        }
      ],
      "source": [
        "# Create NER dataset\n",
        "ner_dataset = NERDataset(valid_examples)\n",
        "prepared_examples = ner_dataset.prepare_for_training()\n",
        "\n",
        "print(f\"üìä Dataset statistics:\")\n",
        "print(f\"  Number of unique labels: {ner_dataset.get_num_labels()}\")\n",
        "print(f\"  Prepared examples: {len(prepared_examples)}\")\n",
        "\n",
        "# Get label statistics\n",
        "label_stats = ner_dataset.get_label_statistics()\n",
        "print(f\"  Total tokens: {label_stats['total_tokens']}\")\n",
        "print(f\"  Entity types found: {len(label_stats['entity_counts'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEtKaFXofIY5"
      },
      "source": [
        "## 6. K-Fold Cross-Validation Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "a002fe80d9634af1aefb41ab98f96134",
            "9098a4a4b1fa4730ba0b3f470ce02c7e",
            "7a6fb49c321c438fbb827b811bb94817",
            "73fd0714c69f491184ae886b2bb51b5f",
            "619504bc4e124a58876e675c3351aad5",
            "2a83b4a620fa42f7a34b3f3e2c56feef",
            "7731d1e1a4fd4bc7b4f68683e303c4aa",
            "7fd2d2293d24487481acc4326c944e33",
            "8557a8b34a5d461788c5fc53750cd551",
            "5f5b0297bc344b3b958db5be45add31a",
            "730785742d7042f9a128ce659bb7c5cc",
            "261633a1e7324635883ec5d3471584cd",
            "989b2e80b2f34ff3ab364a0ca189fe72",
            "45b430cffe044a03841cea735e26416a",
            "81e0a06f17b9448db38a0655e6fcd43c",
            "f9f41eff2e1d47da9db0859d7fd6ee19",
            "4b7b80780feb4a2cad63345c3c30ad3b",
            "520c061745cf49c4a4dec30f533b6934",
            "3c7144e6dbfa4631a4fa3a17fcf1b4c2",
            "97ac6312c63b4e73af608992f729b9eb",
            "e70d8f87eea7412a97150947737cd75d",
            "de57810c045649279cbdb4c0b75a100c",
            "4d0453a4851042efbb9f11a5d4e52b7f",
            "cbfd704e9b764444bc791eae14179355",
            "d803a8fefac046f086b37f7dd85b488d",
            "1702b15fe6204bf49638457f0f7cf672",
            "8fb4351cb1c643ccb7f5163ae5c15575",
            "887046b061fe412fb732d3aba2572ce1",
            "880a2be4cfab44509dda5df45452264f",
            "1be45ac2b32445c7a2f9da61e5336dee",
            "77deedcdfdb1460abe0ac58e039b064a",
            "53be0857fa054da098c93955af7cc25c",
            "f651b15046924a85ba0b665e6135c230"
          ]
        },
        "id": "iOZoMYBNfIY6",
        "outputId": "eda6585c-5f61-4ae7-ecbf-194b6ed17a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up 5-fold cross-validation\n",
            "Total examples: 225\n",
            "Examples per fold (approx): 45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a002fe80d9634af1aefb41ab98f96134",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/83.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "261633a1e7324635883ec5d3471584cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/467 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d0453a4851042efbb9f11a5d4e52b7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded tokenizer for classla/bcms-bertic\n",
            "Tokenizer vocab size: 32000\n"
          ]
        }
      ],
      "source": [
        "# Set up 5-fold cross-validation\n",
        "N_FOLDS = 5\n",
        "kfold = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "# Convert to numpy array for easier indexing\n",
        "examples_array = np.array(prepared_examples, dtype=object)\n",
        "\n",
        "print(f\"Setting up {N_FOLDS}-fold cross-validation\")\n",
        "print(f\"Total examples: {len(prepared_examples)}\")\n",
        "print(f\"Examples per fold (approx): {len(prepared_examples) // N_FOLDS}\")\n",
        "\n",
        "# Load tokenizer (will be used across all folds)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "print(f\"\\nLoaded tokenizer for {MODEL_NAME}\")\n",
        "print(f\"Tokenizer vocab size: {tokenizer.vocab_size}\")\n",
        "\n",
        "# Store results from all folds\n",
        "fold_results = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_fold_helper_functions"
      },
      "source": [
        "## 7. K-Fold Cross-Validation Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_fold_helper_functions_code",
        "outputId": "6a315948-9789-40d1-9b9c-30bcf94f8155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ K-fold helper functions defined successfully!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# K-FOLD CROSS-VALIDATION HELPER FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def prepare_fold_data(train_examples, val_examples, tokenizer, ner_dataset):\n",
        "    \"\"\"\n",
        "    Prepare training and validation datasets for a specific fold.\n",
        "\n",
        "    Args:\n",
        "        train_examples: Training examples for this fold\n",
        "        val_examples: Validation examples for this fold\n",
        "        tokenizer: Tokenizer instance\n",
        "        ner_dataset: NER dataset instance\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_dataset, val_dataset, data_collator)\n",
        "    \"\"\"\n",
        "    # Tokenize datasets with sliding window\n",
        "    train_tokenized = tokenize_and_align_labels_with_sliding_window(\n",
        "        train_examples, tokenizer, ner_dataset.label_to_id,\n",
        "        max_length=model_config['max_length'], stride=model_config['stride']\n",
        "    )\n",
        "\n",
        "    val_tokenized = tokenize_and_align_labels_with_sliding_window(\n",
        "        val_examples, tokenizer, ner_dataset.label_to_id,\n",
        "        max_length=model_config['max_length'], stride=model_config['stride']\n",
        "    )\n",
        "\n",
        "    # Create HuggingFace datasets\n",
        "    train_dataset, val_dataset, _ = create_huggingface_datasets(\n",
        "        train_tokenized, val_tokenized, val_tokenized  # Using val as placeholder for test\n",
        "    )\n",
        "\n",
        "    # Data collator\n",
        "    data_collator = DataCollatorForTokenClassification(\n",
        "        tokenizer=tokenizer,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    return train_dataset, val_dataset, data_collator\n",
        "\n",
        "print(\"‚úÖ K-fold helper functions defined successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_fold_helper_functions_2",
        "outputId": "ebc4e0ef-7980-41a8-c348-dce2cc61fea4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model and trainer creation function defined successfully!\n"
          ]
        }
      ],
      "source": [
        "def create_model_and_trainer(fold_num, train_dataset, val_dataset, data_collator, tokenizer, ner_dataset, device):\n",
        "    \"\"\"\n",
        "    Create model and trainer for a specific fold.\n",
        "\n",
        "    Args:\n",
        "        fold_num: Current fold number\n",
        "        train_dataset: Training dataset for this fold\n",
        "        val_dataset: Validation dataset for this fold\n",
        "        data_collator: Data collator\n",
        "        tokenizer: Tokenizer instance\n",
        "        ner_dataset: NER dataset instance\n",
        "        device: Device to use (cuda/cpu)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, trainer, fold_output_dir)\n",
        "    \"\"\"\n",
        "    # Create fold-specific output directory\n",
        "    fold_output_dir = f\"{OUTPUT_DIR}/fold_{fold_num}\"\n",
        "    import os\n",
        "    os.makedirs(fold_output_dir, exist_ok=True)\n",
        "\n",
        "    # Load fresh model for this fold\n",
        "    model, _ = load_model_and_tokenizer(\n",
        "        MODEL_NAME,\n",
        "        ner_dataset.get_num_labels(),\n",
        "        ner_dataset.id_to_label,\n",
        "        ner_dataset.label_to_id\n",
        "    )\n",
        "\n",
        "    # Move model to device\n",
        "    model.to(device)\n",
        "\n",
        "    # Create training arguments for this fold\n",
        "    training_args = create_training_arguments(\n",
        "        output_dir=fold_output_dir,\n",
        "        num_epochs=model_config['num_epochs'],\n",
        "        batch_size=model_config['batch_size'],\n",
        "        learning_rate=model_config['learning_rate'],\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=50,\n",
        "        eval_steps=100,\n",
        "        save_steps=500,\n",
        "        early_stopping_patience=3\n",
        "    )\n",
        "\n",
        "    # Create trainer\n",
        "    trainer = create_trainer(\n",
        "        model=model,\n",
        "        training_args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        val_dataset=val_dataset,\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=tokenizer,\n",
        "        id_to_label=ner_dataset.id_to_label,\n",
        "        early_stopping_patience=3\n",
        "    )\n",
        "\n",
        "    print(f\"Trainer initialized for fold {fold_num}\")\n",
        "    return model, trainer, fold_output_dir\n",
        "\n",
        "print(\"‚úÖ Model and trainer creation function defined successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_fold_helper_functions_3",
        "outputId": "1564536d-fe20-420b-d667-8008fdffe972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Training and evaluation helper function defined successfully!\n"
          ]
        }
      ],
      "source": [
        "def train_and_evaluate_fold(fold_num, trainer, val_dataset, ner_dataset):\n",
        "    \"\"\"\n",
        "    Train and evaluate a model for a specific fold.\n",
        "\n",
        "    Args:\n",
        "        fold_num: Current fold number\n",
        "        trainer: Trainer instance\n",
        "        val_dataset: Validation dataset for this fold\n",
        "        ner_dataset: NER dataset instance\n",
        "\n",
        "    Returns:\n",
        "        dict: Fold results including metrics\n",
        "    \"\"\"\n",
        "    print(f\"\\nüèãÔ∏è  Training fold {fold_num}...\")\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    print(f\"üíæ Saving model for fold {fold_num}...\")\n",
        "    trainer.save_model()\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    print(f\"üìä Evaluating fold {fold_num}...\")\n",
        "    eval_results = detailed_evaluation(\n",
        "        trainer, val_dataset, f\"Fold {fold_num} Validation\", ner_dataset.id_to_label\n",
        "    )\n",
        "\n",
        "    # Extract metrics\n",
        "    fold_result = {\n",
        "        'fold': fold_num,\n",
        "        'precision': eval_results['precision'],\n",
        "        'recall': eval_results['recall'],\n",
        "        'f1': eval_results['f1'],\n",
        "        'accuracy': eval_results['accuracy'],\n",
        "        'true_predictions': eval_results['true_predictions'],\n",
        "        'true_labels': eval_results['true_labels']\n",
        "    }\n",
        "\n",
        "    print(f\"\\nFold {fold_num} completed successfully!\")\n",
        "    return fold_result\n",
        "\n",
        "print(\"‚úÖ Training and evaluation helper function defined successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_fold_main_training"
      },
      "source": [
        "## 8. K-Fold Cross-Validation Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k_fold_main_loop",
        "outputId": "c26f9699-3848-49d2-84e7-d46f3866cb12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "\n",
            "================================================================================\n",
            "STARTING 5-FOLD CROSS-VALIDATION\n",
            "================================================================================\n",
            "Total examples: 225\n",
            "Model: classla/bcms-bertic\n",
            "Device: cpu\n",
            "\n",
            "================================================================================\n",
            "FOLD 1/5\n",
            "================================================================================\n",
            "Train indices: 180, Val indices: 45\n",
            "Training examples: 180\n",
            "Validation examples: 45\n",
            "\n",
            "üî§ Preparing data for fold 1...\n",
            "üì¶ Created HuggingFace datasets:\n",
            "  Training: 1845 examples\n",
            "  Validation: 500 examples\n",
            "  Test: 500 examples\n",
            "üì¶ Fold 1 datasets:\n",
            "  Training: 1845 examples\n",
            "  Validation: 500 examples\n",
            "\n",
            "ü§ñ Creating model and trainer for fold 1...\n",
            "üîÑ Loading model and tokenizer...\n",
            "üì• Model: classla/bcms-bertic\n",
            "üè∑Ô∏è  Number of labels: 29\n",
            "‚úÖ Loaded tokenizer (vocab size: 32000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded model (parameters: 110,049,053)\n",
            "üñ•Ô∏è  Device: cpu\n",
            "‚öôÔ∏è  Training configuration:\n",
            "  Epochs: 8\n",
            "  Batch size: 4\n",
            "  Learning rate: 3e-05\n",
            "  Warmup steps: 500\n",
            "  Weight decay: 0.01\n",
            "  Early stopping patience: 3\n",
            "üèãÔ∏è  Created trainer with early stopping (patience: 3)\n",
            "üìä Training dataset size: 1845\n",
            "üìä Validation dataset size: 500\n",
            "Trainer initialized for fold 1\n",
            "\n",
            "üèãÔ∏è  Training fold 1...\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpericapero1\u001b[0m (\u001b[33mpericapero1-faculty-of-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251001_124732-2kzeevwz</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/pericapero1-faculty-of-/huggingface/runs/2kzeevwz' target=\"_blank\">stilted-terrain-30</a></strong> to <a href='https://wandb.ai/pericapero1-faculty-of-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/pericapero1-faculty-of-/huggingface' target=\"_blank\">https://wandb.ai/pericapero1-faculty-of-/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/pericapero1-faculty-of-/huggingface/runs/2kzeevwz' target=\"_blank\">https://wandb.ai/pericapero1-faculty-of-/huggingface/runs/2kzeevwz</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17' max='3696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  17/3696 07:46 < 31:46:00, 0.03 it/s, Epoch 0.03/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Check device availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Main K-Fold Cross-Validation Loop\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"STARTING {N_FOLDS}-FOLD CROSS-VALIDATION\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Total examples: {len(examples_array)}\")\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Execute K-Fold training\n",
        "for fold_num, (train_idx, val_idx) in enumerate(kfold.split(examples_array), 1):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"FOLD {fold_num}/{N_FOLDS}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Train indices: {len(train_idx)}, Val indices: {len(val_idx)}\")\n",
        "\n",
        "    # Get fold data\n",
        "    train_examples = examples_array[train_idx].tolist()\n",
        "    val_examples = examples_array[val_idx].tolist()\n",
        "\n",
        "    print(f\"Training examples: {len(train_examples)}\")\n",
        "    print(f\"Validation examples: {len(val_examples)}\")\n",
        "\n",
        "    # Prepare data for this fold\n",
        "    print(f\"\\nüî§ Preparing data for fold {fold_num}...\")\n",
        "    train_dataset, val_dataset, data_collator = prepare_fold_data(\n",
        "        train_examples, val_examples, tokenizer, ner_dataset\n",
        "    )\n",
        "\n",
        "    print(f\"üì¶ Fold {fold_num} datasets:\")\n",
        "    print(f\"  Training: {len(train_dataset)} examples\")\n",
        "    print(f\"  Validation: {len(val_dataset)} examples\")\n",
        "\n",
        "    # Create model and trainer for this fold\n",
        "    print(f\"\\nü§ñ Creating model and trainer for fold {fold_num}...\")\n",
        "    model, trainer, fold_output_dir = create_model_and_trainer(\n",
        "        fold_num, train_dataset, val_dataset, data_collator, tokenizer, ner_dataset, device\n",
        "    )\n",
        "\n",
        "    # Train and evaluate this fold\n",
        "    fold_result = train_and_evaluate_fold(fold_num, trainer, val_dataset, ner_dataset)\n",
        "    fold_results.append(fold_result)\n",
        "\n",
        "    # Clean up to free memory\n",
        "    del model, trainer, train_dataset, val_dataset\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "    print(f\"\\n‚úÖ Fold {fold_num} completed!\")\n",
        "    print(f\"   Precision: {fold_result['precision']:.4f}\")\n",
        "    print(f\"   Recall: {fold_result['recall']:.4f}\")\n",
        "    print(f\"   F1-Score: {fold_result['f1']:.4f}\")\n",
        "    print(f\"   Accuracy: {fold_result['accuracy']:.4f}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"K-FOLD CROSS-VALIDATION COMPLETED!\")\n",
        "print(f\"{'='*80}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_fold_results_analysis"
      },
      "source": [
        "## 9. K-Fold Results Analysis and Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_fold_summary_stats"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# K-FOLD RESULTS SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"K-FOLD CROSS-VALIDATION RESULTS SUMMARY\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Extract metrics from all folds\n",
        "precisions = [result['precision'] for result in fold_results]\n",
        "recalls = [result['recall'] for result in fold_results]\n",
        "f1_scores = [result['f1'] for result in fold_results]\n",
        "accuracies = [result['accuracy'] for result in fold_results]\n",
        "\n",
        "# Calculate statistics\n",
        "print(f\"\\nüìä PERFORMANCE METRICS ACROSS {N_FOLDS} FOLDS:\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "print(f\"\\nüéØ PRECISION:\")\n",
        "print(f\"  Mean: {np.mean(precisions):.4f} ¬± {np.std(precisions):.4f}\")\n",
        "print(f\"  Min:  {np.min(precisions):.4f} (Fold {np.argmin(precisions) + 1})\")\n",
        "print(f\"  Max:  {np.max(precisions):.4f} (Fold {np.argmax(precisions) + 1})\")\n",
        "\n",
        "print(f\"\\nüéØ RECALL:\")\n",
        "print(f\"  Mean: {np.mean(recalls):.4f} ¬± {np.std(recalls):.4f}\")\n",
        "print(f\"  Min:  {np.min(recalls):.4f} (Fold {np.argmin(recalls) + 1})\")\n",
        "print(f\"  Max:  {np.max(recalls):.4f} (Fold {np.argmax(recalls) + 1})\")\n",
        "\n",
        "print(f\"\\nüéØ F1-SCORE:\")\n",
        "print(f\"  Mean: {np.mean(f1_scores):.4f} ¬± {np.std(f1_scores):.4f}\")\n",
        "print(f\"  Min:  {np.min(f1_scores):.4f} (Fold {np.argmin(f1_scores) + 1})\")\n",
        "print(f\"  Max:  {np.max(f1_scores):.4f} (Fold {np.argmax(f1_scores) + 1})\")\n",
        "\n",
        "print(f\"\\nüéØ ACCURACY:\")\n",
        "print(f\"  Mean: {np.mean(accuracies):.4f} ¬± {np.std(accuracies):.4f}\")\n",
        "print(f\"  Min:  {np.min(accuracies):.4f} (Fold {np.argmin(accuracies) + 1})\")\n",
        "print(f\"  Max:  {np.max(accuracies):.4f} (Fold {np.argmax(accuracies) + 1})\")\n",
        "\n",
        "# Individual fold results\n",
        "print(f\"\\nüìã INDIVIDUAL FOLD RESULTS:\")\n",
        "print(f\"{'='*50}\")\n",
        "for i, result in enumerate(fold_results, 1):\n",
        "    print(f\"Fold {i}: P={result['precision']:.4f}, R={result['recall']:.4f}, F1={result['f1']:.4f}, Acc={result['accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_fold_visualization"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# VISUALIZATION OF K-FOLD RESULTS\n",
        "# ============================================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create visualization of fold results\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle(f'{N_FOLDS}-Fold Cross-Validation Results - Base BERT Model', fontsize=16, fontweight='bold')\n",
        "\n",
        "fold_numbers = list(range(1, N_FOLDS + 1))\n",
        "\n",
        "# Precision plot\n",
        "ax1.bar(fold_numbers, precisions, alpha=0.7, color='skyblue', edgecolor='navy')\n",
        "ax1.set_title('Precision by Fold', fontweight='bold')\n",
        "ax1.set_xlabel('Fold')\n",
        "ax1.set_ylabel('Precision')\n",
        "ax1.set_ylim(0, 1)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "for i, v in enumerate(precisions):\n",
        "    ax1.text(i+1, v+0.01, f'{v:.3f}', ha='center', va='bottom')\n",
        "\n",
        "# Recall plot\n",
        "ax2.bar(fold_numbers, recalls, alpha=0.7, color='lightgreen', edgecolor='darkgreen')\n",
        "ax2.set_title('Recall by Fold', fontweight='bold')\n",
        "ax2.set_xlabel('Fold')\n",
        "ax2.set_ylabel('Recall')\n",
        "ax2.set_ylim(0, 1)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "for i, v in enumerate(recalls):\n",
        "    ax2.text(i+1, v+0.01, f'{v:.3f}', ha='center', va='bottom')\n",
        "\n",
        "# F1-Score plot\n",
        "ax3.bar(fold_numbers, f1_scores, alpha=0.7, color='gold', edgecolor='orange')\n",
        "ax3.set_title('F1-Score by Fold', fontweight='bold')\n",
        "ax3.set_xlabel('Fold')\n",
        "ax3.set_ylabel('F1-Score')\n",
        "ax3.set_ylim(0, 1)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "for i, v in enumerate(f1_scores):\n",
        "    ax3.text(i+1, v+0.01, f'{v:.3f}', ha='center', va='bottom')\n",
        "\n",
        "# Accuracy plot\n",
        "ax4.bar(fold_numbers, accuracies, alpha=0.7, color='lightcoral', edgecolor='darkred')\n",
        "ax4.set_title('Accuracy by Fold', fontweight='bold')\n",
        "ax4.set_xlabel('Fold')\n",
        "ax4.set_ylabel('Accuracy')\n",
        "ax4.set_ylim(0, 1)\n",
        "ax4.grid(True, alpha=0.3)\n",
        "for i, v in enumerate(accuracies):\n",
        "    ax4.text(i+1, v+0.01, f'{v:.3f}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_fold_boxplot"
      },
      "outputs": [],
      "source": [
        "# Box plot for metric distribution\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "metrics_data = [precisions, recalls, f1_scores, accuracies]\n",
        "labels = ['Precision', 'Recall', 'F1-Score', 'Accuracy']\n",
        "\n",
        "box_plot = ax.boxplot(metrics_data, labels=labels, patch_artist=True)\n",
        "colors = ['skyblue', 'lightgreen', 'gold', 'lightcoral']\n",
        "for patch, color in zip(box_plot['boxes'], colors):\n",
        "    patch.set_facecolor(color)\n",
        "    patch.set_alpha(0.7)\n",
        "\n",
        "ax.set_title(f'{N_FOLDS}-Fold Cross-Validation Metrics Distribution', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Score')\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim(0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_fold_save_results"
      },
      "source": [
        "## 10. Save Results and Final Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_fold_save_results_code"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SAVE RESULTS TO FILE\n",
        "# ============================================================================\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Create results summary\n",
        "results_summary = {\n",
        "    'experiment_info': {\n",
        "        'model_name': MODEL_NAME,\n",
        "        'n_folds': N_FOLDS,\n",
        "        'total_examples': len(prepared_examples),\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'device': str(device)\n",
        "    },\n",
        "    'overall_metrics': {\n",
        "        'precision': {\n",
        "            'mean': float(np.mean(precisions)),\n",
        "            'std': float(np.std(precisions)),\n",
        "            'min': float(np.min(precisions)),\n",
        "            'max': float(np.max(precisions))\n",
        "        },\n",
        "        'recall': {\n",
        "            'mean': float(np.mean(recalls)),\n",
        "            'std': float(np.std(recalls)),\n",
        "            'min': float(np.min(recalls)),\n",
        "            'max': float(np.max(recalls))\n",
        "        },\n",
        "        'f1_score': {\n",
        "            'mean': float(np.mean(f1_scores)),\n",
        "            'std': float(np.std(f1_scores)),\n",
        "            'min': float(np.min(f1_scores)),\n",
        "            'max': float(np.max(f1_scores))\n",
        "        },\n",
        "        'accuracy': {\n",
        "            'mean': float(np.mean(accuracies)),\n",
        "            'std': float(np.std(accuracies)),\n",
        "            'min': float(np.min(accuracies)),\n",
        "            'max': float(np.max(accuracies))\n",
        "        }\n",
        "    },\n",
        "    'fold_results': [\n",
        "        {\n",
        "            'fold': result['fold'],\n",
        "            'precision': float(result['precision']),\n",
        "            'recall': float(result['recall']),\n",
        "            'f1': float(result['f1']),\n",
        "            'accuracy': float(result['accuracy'])\n",
        "        }\n",
        "        for result in fold_results\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Save results to JSON\n",
        "results_file = f\"{OUTPUT_DIR}/5fold_cv_results.json\"\n",
        "with open(results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(results_summary, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"‚úÖ Results saved to: {results_file}\")\n",
        "\n",
        "# Create CSV for easy analysis\n",
        "df_results = pd.DataFrame([\n",
        "    {\n",
        "        'Fold': result['fold'],\n",
        "        'Precision': result['precision'],\n",
        "        'Recall': result['recall'],\n",
        "        'F1-Score': result['f1'],\n",
        "        'Accuracy': result['accuracy']\n",
        "    }\n",
        "    for result in fold_results\n",
        "])\n",
        "\n",
        "# Add summary row\n",
        "summary_row = {\n",
        "    'Fold': 'Mean ¬± Std',\n",
        "    'Precision': f\"{np.mean(precisions):.4f} ¬± {np.std(precisions):.4f}\",\n",
        "    'Recall': f\"{np.mean(recalls):.4f} ¬± {np.std(recalls):.4f}\",\n",
        "    'F1-Score': f\"{np.mean(f1_scores):.4f} ¬± {np.std(f1_scores):.4f}\",\n",
        "    'Accuracy': f\"{np.mean(accuracies):.4f} ¬± {np.std(accuracies):.4f}\"\n",
        "}\n",
        "\n",
        "df_results = pd.concat([df_results, pd.DataFrame([summary_row])], ignore_index=True)\n",
        "\n",
        "csv_file = f\"{OUTPUT_DIR}/5fold_cv_results.csv\"\n",
        "df_results.to_csv(csv_file, index=False)\n",
        "print(f\"‚úÖ Results CSV saved to: {csv_file}\")\n",
        "\n",
        "# Display final summary table\n",
        "print(f\"\\nüìä FINAL RESULTS TABLE:\")\n",
        "print(df_results.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "## 11. Conclusion\n",
        "\n",
        "This notebook successfully implemented 5-fold cross-validation for the Serbian Legal NER pipeline using the base BERT model (classla/bcms-bertic).\n",
        "\n",
        "### Key Achievements:\n",
        "- ‚úÖ **Robust Evaluation**: 5-fold cross-validation provides reliable performance estimates\n",
        "- ‚úÖ **Comprehensive Metrics**: Precision, recall, F1-score, and accuracy tracked across all folds\n",
        "- ‚úÖ **Statistical Analysis**: Mean and standard deviation calculated for all metrics\n",
        "- ‚úÖ **Visualization**: Clear charts showing performance across folds\n",
        "- ‚úÖ **Results Persistence**: JSON and CSV files saved for further analysis\n",
        "\n",
        "### Next Steps:\n",
        "1. **Compare with Other Models**: Use this same framework to evaluate other model variants\n",
        "2. **Hyperparameter Tuning**: Optimize learning rate, batch size, and other parameters\n",
        "3. **Error Analysis**: Examine misclassified entities to identify improvement opportunities\n",
        "4. **Ensemble Methods**: Combine predictions from multiple folds for better performance\n",
        "\n",
        "The 5-fold cross-validation framework is now ready to be applied to other models in your pipeline!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cpu_torch_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1702b15fe6204bf49638457f0f7cf672": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53be0857fa054da098c93955af7cc25c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f651b15046924a85ba0b665e6135c230",
            "value": "‚Äá231k/?‚Äá[00:00&lt;00:00,‚Äá1.23MB/s]"
          }
        },
        "1be45ac2b32445c7a2f9da61e5336dee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "261633a1e7324635883ec5d3471584cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_989b2e80b2f34ff3ab364a0ca189fe72",
              "IPY_MODEL_45b430cffe044a03841cea735e26416a",
              "IPY_MODEL_81e0a06f17b9448db38a0655e6fcd43c"
            ],
            "layout": "IPY_MODEL_f9f41eff2e1d47da9db0859d7fd6ee19"
          }
        },
        "2a83b4a620fa42f7a34b3f3e2c56feef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c7144e6dbfa4631a4fa3a17fcf1b4c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45b430cffe044a03841cea735e26416a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c7144e6dbfa4631a4fa3a17fcf1b4c2",
            "max": 467,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97ac6312c63b4e73af608992f729b9eb",
            "value": 467
          }
        },
        "4b7b80780feb4a2cad63345c3c30ad3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d0453a4851042efbb9f11a5d4e52b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbfd704e9b764444bc791eae14179355",
              "IPY_MODEL_d803a8fefac046f086b37f7dd85b488d",
              "IPY_MODEL_1702b15fe6204bf49638457f0f7cf672"
            ],
            "layout": "IPY_MODEL_8fb4351cb1c643ccb7f5163ae5c15575"
          }
        },
        "520c061745cf49c4a4dec30f533b6934": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53be0857fa054da098c93955af7cc25c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f5b0297bc344b3b958db5be45add31a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "619504bc4e124a58876e675c3351aad5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "730785742d7042f9a128ce659bb7c5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73fd0714c69f491184ae886b2bb51b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f5b0297bc344b3b958db5be45add31a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_730785742d7042f9a128ce659bb7c5cc",
            "value": "‚Äá83.0/83.0‚Äá[00:00&lt;00:00,‚Äá780B/s]"
          }
        },
        "7731d1e1a4fd4bc7b4f68683e303c4aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77deedcdfdb1460abe0ac58e039b064a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a6fb49c321c438fbb827b811bb94817": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fd2d2293d24487481acc4326c944e33",
            "max": 83,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8557a8b34a5d461788c5fc53750cd551",
            "value": 83
          }
        },
        "7fd2d2293d24487481acc4326c944e33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81e0a06f17b9448db38a0655e6fcd43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e70d8f87eea7412a97150947737cd75d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_de57810c045649279cbdb4c0b75a100c",
            "value": "‚Äá467/467‚Äá[00:00&lt;00:00,‚Äá4.88kB/s]"
          }
        },
        "8557a8b34a5d461788c5fc53750cd551": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "880a2be4cfab44509dda5df45452264f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "887046b061fe412fb732d3aba2572ce1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fb4351cb1c643ccb7f5163ae5c15575": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9098a4a4b1fa4730ba0b3f470ce02c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a83b4a620fa42f7a34b3f3e2c56feef",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7731d1e1a4fd4bc7b4f68683e303c4aa",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "97ac6312c63b4e73af608992f729b9eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "989b2e80b2f34ff3ab364a0ca189fe72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b7b80780feb4a2cad63345c3c30ad3b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_520c061745cf49c4a4dec30f533b6934",
            "value": "config.json:‚Äá100%"
          }
        },
        "a002fe80d9634af1aefb41ab98f96134": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9098a4a4b1fa4730ba0b3f470ce02c7e",
              "IPY_MODEL_7a6fb49c321c438fbb827b811bb94817",
              "IPY_MODEL_73fd0714c69f491184ae886b2bb51b5f"
            ],
            "layout": "IPY_MODEL_619504bc4e124a58876e675c3351aad5"
          }
        },
        "cbfd704e9b764444bc791eae14179355": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_887046b061fe412fb732d3aba2572ce1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_880a2be4cfab44509dda5df45452264f",
            "value": "vocab.txt:‚Äá"
          }
        },
        "d803a8fefac046f086b37f7dd85b488d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1be45ac2b32445c7a2f9da61e5336dee",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77deedcdfdb1460abe0ac58e039b064a",
            "value": 1
          }
        },
        "de57810c045649279cbdb4c0b75a100c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e70d8f87eea7412a97150947737cd75d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f651b15046924a85ba0b665e6135c230": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9f41eff2e1d47da9db0859d7fd6ee19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
