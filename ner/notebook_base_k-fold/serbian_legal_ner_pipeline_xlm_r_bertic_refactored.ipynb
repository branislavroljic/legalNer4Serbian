{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCxJ3lfIjTOm"
      },
      "source": [
        "# Serbian Legal NER Pipeline with XLM-RoBERTa BERTiƒá - Refactored\n",
        "\n",
        "This notebook demonstrates the multilingual XLM-RoBERTa BERTiƒá approach for Serbian Legal NER using shared modules.\n",
        "XLM-RoBERTa BERTiƒá combines multilingual capabilities with Serbian language specialization.\n",
        "\n",
        "## Key Features:\n",
        "- **Multilingual Foundation**: XLM-RoBERTa base with cross-lingual knowledge\n",
        "- **Serbian Specialization**: Fine-tuned on Serbian texts (BERTiƒá)\n",
        "- **Cross-lingual Transfer**: Benefits from multilingual pretraining\n",
        "- **Robust Performance**: Better generalization across language variants\n",
        "\n",
        "## Model Comparison:\n",
        "- **BERTiƒá**: Monolingual Serbian BERT\n",
        "- **XLM-R BERTiƒá**: Multilingual XLM-RoBERTa adapted for Serbian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGTyacPF64Th"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install transformers torch datasets tokenizers scikit-learn seqeval pandas numpy matplotlib seaborn tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import shared modules\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add the shared modules to path\n",
        "sys.path.append('/content/drive/MyDrive/NER_Master/ner/shared')\n",
        "\n",
        "# Reload shared modules to get latest changes\n",
        "import importlib\n",
        "import shared\n",
        "import shared.model_utils\n",
        "import shared.data_processing\n",
        "import shared.dataset\n",
        "import shared.evaluation\n",
        "import shared.config\n",
        "importlib.reload(shared.config)\n",
        "importlib.reload(shared.data_processing)\n",
        "importlib.reload(shared.dataset)\n",
        "importlib.reload(shared.model_utils)\n",
        "importlib.reload(shared.evaluation)\n",
        "importlib.reload(shared)\n",
        "\n",
        "# Import from shared modules\n",
        "from shared import (\n",
        "    # Configuration\n",
        "    ENTITY_TYPES, BIO_LABELS, DEFAULT_TRAINING_ARGS,\n",
        "    get_model_config, get_paths, setup_environment,\n",
        "    \n",
        "    # Data processing\n",
        "    LabelStudioToBIOConverter, load_labelstudio_data, \n",
        "    analyze_labelstudio_data, validate_bio_examples,\n",
        "    \n",
        "    # Dataset\n",
        "    NERDataset, split_dataset, tokenize_and_align_labels_with_sliding_window,\n",
        "    print_sequence_analysis, create_huggingface_datasets,\n",
        "    \n",
        "    # Model utilities\n",
        "    load_model_and_tokenizer, create_training_arguments, create_trainer,\n",
        "    detailed_evaluation, save_model_info, setup_device_and_seed,\n",
        "    \n",
        "    # Inference and Evaluation\n",
        "    load_inference_pipeline,\n",
        "    generate_evaluation_report, plot_training_history, plot_entity_distribution\n",
        ")\n",
        "\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "# Setup device and random seed\n",
        "device = setup_device_and_seed(42)\n",
        "print(f\"üîß Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration and Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup environment and paths for Google Colab\n",
        "env_setup = setup_environment(use_local=False, create_dirs=True)\n",
        "paths = env_setup['paths']\n",
        "\n",
        "# Model configuration for XLM-R BERTiƒá\n",
        "MODEL_NAME = \"classla/xlm-r-bertic\"\n",
        "model_config = get_model_config(MODEL_NAME)\n",
        "\n",
        "# Output directory\n",
        "OUTPUT_DIR = f\"{paths['models_dir']}/xlm_r_bertic_refactored\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"üîß XLM-R BERTiƒá Configuration:\")\n",
        "print(f\"  Model: {MODEL_NAME}\")\n",
        "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
        "print(f\"  Entity types: {len(ENTITY_TYPES)}\")\n",
        "print(f\"  BIO labels: {len(BIO_LABELS)}\")\n",
        "print(f\"  Max length: {model_config['max_length']}\")\n",
        "print(f\"  Learning rate: {model_config['learning_rate']}\")\n",
        "print(f\"  Batch size: {model_config['batch_size']}\")\n",
        "print(f\"  Epochs: {model_config['num_epochs']}\")\n",
        "\n",
        "print(f\"\\nüåç Multilingual advantages:\")\n",
        "print(f\"  ‚úÖ Cross-lingual knowledge transfer\")\n",
        "print(f\"  ‚úÖ Better handling of code-switching\")\n",
        "print(f\"  ‚úÖ Robust to language variants\")\n",
        "print(f\"  ‚úÖ Larger vocabulary coverage\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and analyze LabelStudio data\n",
        "labelstudio_data = load_labelstudio_data(paths['labelstudio_json'])\n",
        "\n",
        "if labelstudio_data:\n",
        "    analysis = analyze_labelstudio_data(labelstudio_data)\n",
        "    \n",
        "    # Convert to BIO format\n",
        "    converter = LabelStudioToBIOConverter(\n",
        "        judgments_dir=paths['judgments_dir'],\n",
        "        labelstudio_files_dir=paths.get('labelstudio_files_dir')\n",
        "    )\n",
        "    \n",
        "    bio_examples = converter.convert_to_bio(labelstudio_data)\n",
        "    print(f\"‚úÖ Converted {len(bio_examples)} examples to BIO format\")\n",
        "    \n",
        "    # Validate BIO examples\n",
        "    valid_examples, stats = validate_bio_examples(bio_examples)\n",
        "    print(f\"üìä Validation complete: {stats['valid_examples']} valid examples\")\n",
        "else:\n",
        "    print(\"‚ùå No data loaded. Please check your paths.\")\n",
        "    raise Exception(\"Data loading failed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Dataset Preparation and Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create NER dataset\n",
        "ner_dataset = NERDataset(valid_examples)\n",
        "prepared_examples = ner_dataset.prepare_for_training()\n",
        "\n",
        "# Split dataset\n",
        "train_examples, val_examples, test_examples = split_dataset(\n",
        "    prepared_examples, test_size=0.2, val_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"üìä Dataset split:\")\n",
        "print(f\"  Training: {len(train_examples)} examples\")\n",
        "print(f\"  Validation: {len(val_examples)} examples\")\n",
        "print(f\"  Test: {len(test_examples)} examples\")\n",
        "print(f\"  Total labels: {ner_dataset.get_num_labels()}\")\n",
        "\n",
        "# Show label statistics\n",
        "label_stats = ner_dataset.get_label_statistics()\n",
        "print(f\"\\nüìà Label distribution:\")\n",
        "for entity, count in sorted(label_stats['entity_counts'].items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "    print(f\"  {entity}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. XLM-R BERTiƒá Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load XLM-R BERTiƒá model and tokenizer\n",
        "model, tokenizer = load_model_and_tokenizer(\n",
        "    MODEL_NAME, \n",
        "    ner_dataset.get_num_labels(),\n",
        "    ner_dataset.id_to_label,\n",
        "    ner_dataset.label_to_id\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ XLM-R BERTiƒá model loaded successfully\")\n",
        "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"üåç Multilingual model with Serbian specialization\")\n",
        "\n",
        "# Show tokenizer info\n",
        "print(f\"\\nüî§ Tokenizer information:\")\n",
        "print(f\"  Vocabulary size: {tokenizer.vocab_size:,}\")\n",
        "print(f\"  Model max length: {tokenizer.model_max_length}\")\n",
        "print(f\"  Special tokens: {len(tokenizer.special_tokens_map)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Data Tokenization with XLM-R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze sequence lengths with XLM-R tokenizer\n",
        "print(\"üìè Sequence length analysis with XLM-R tokenizer:\")\n",
        "print(\"\\nTraining set:\")\n",
        "print_sequence_analysis(train_examples, tokenizer)\n",
        "print(\"\\nValidation set:\")\n",
        "print_sequence_analysis(val_examples, tokenizer)\n",
        "\n",
        "# Tokenize datasets with sliding window\n",
        "print(\"\\nüî§ Tokenizing datasets with XLM-R tokenizer...\")\n",
        "\n",
        "train_tokenized = tokenize_and_align_labels_with_sliding_window(\n",
        "    train_examples, tokenizer, ner_dataset.label_to_id, \n",
        "    max_length=model_config['max_length'], \n",
        "    stride=model_config['stride']\n",
        ")\n",
        "\n",
        "val_tokenized = tokenize_and_align_labels_with_sliding_window(\n",
        "    val_examples, tokenizer, ner_dataset.label_to_id,\n",
        "    max_length=model_config['max_length'], \n",
        "    stride=model_config['stride']\n",
        ")\n",
        "\n",
        "test_tokenized = tokenize_and_align_labels_with_sliding_window(\n",
        "    test_examples, tokenizer, ner_dataset.label_to_id,\n",
        "    max_length=model_config['max_length'], \n",
        "    stride=model_config['stride']\n",
        ")\n",
        "\n",
        "# Create HuggingFace datasets\n",
        "train_dataset, val_dataset, test_dataset = create_huggingface_datasets(\n",
        "    train_tokenized, val_tokenized, test_tokenized\n",
        ")\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorForTokenClassification(\n",
        "    tokenizer=tokenizer,\n",
        "    padding=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Tokenization complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create training arguments for XLM-R BERTiƒá\n",
        "training_args = create_training_arguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=model_config['num_epochs'],\n",
        "    per_device_train_batch_size=model_config['batch_size'],\n",
        "    per_device_eval_batch_size=model_config['batch_size'],\n",
        "    learning_rate=model_config['learning_rate'],\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    eval_steps=100,\n",
        "    save_steps=500,\n",
        "    early_stopping_patience=3\n",
        ")\n",
        "\n",
        "# Create trainer\n",
        "trainer = create_trainer(\n",
        "    model=model,\n",
        "    training_args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    val_dataset=val_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    id_to_label=ner_dataset.id_to_label,\n",
        "    early_stopping_patience=3\n",
        ")\n",
        "\n",
        "print(\"üèãÔ∏è  XLM-R BERTiƒá trainer created successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start XLM-R BERTiƒá training\n",
        "print(\"üöÄ Starting XLM-R BERTiƒá training...\")\n",
        "print(\"üåç Leveraging multilingual knowledge for Serbian legal NER\")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "print(\"üíæ Saving XLM-R BERTiƒá model...\")\n",
        "trainer.save_model()\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "\n",
        "# Save model info with multilingual details\n",
        "save_model_info(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    model_name=MODEL_NAME,\n",
        "    model_type=\"xlm_r_bertic\",\n",
        "    num_labels=ner_dataset.get_num_labels(),\n",
        "    id_to_label=ner_dataset.id_to_label,\n",
        "    label_to_id=ner_dataset.label_to_id,\n",
        "    training_args=training_args,\n",
        "    additional_info={\n",
        "        \"base_architecture\": \"XLM-RoBERTa\",\n",
        "        \"language_specialization\": \"Serbian (BERTiƒá)\",\n",
        "        \"multilingual\": True,\n",
        "        \"vocab_size\": tokenizer.vocab_size,\n",
        "        \"cross_lingual\": True\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"‚úÖ XLM-R BERTiƒá training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate XLM-R BERTiƒá model on test set\n",
        "print(\"üìä Evaluating XLM-R BERTiƒá model on test set...\")\n",
        "\n",
        "test_results = detailed_evaluation(\n",
        "    trainer=trainer,\n",
        "    dataset=test_dataset,\n",
        "    dataset_name=\"Test (XLM-R BERTiƒá)\",\n",
        "    id_to_label=ner_dataset.id_to_label\n",
        ")\n",
        "\n",
        "print(f\"\\nüìà XLM-R BERTiƒá Test Results:\")\n",
        "print(f\"  Precision: {test_results['precision']:.4f}\")\n",
        "print(f\"  Recall: {test_results['recall']:.4f}\")\n",
        "print(f\"  F1-score: {test_results['f1']:.4f}\")\n",
        "print(f\"  Accuracy: {test_results['accuracy']:.4f}\")\n",
        "\n",
        "print(f\"\\nüí° Expected advantages of XLM-R BERTiƒá:\")\n",
        "print(f\"  ‚úÖ Better handling of multilingual contexts\")\n",
        "print(f\"  ‚úÖ Robust to language variations\")\n",
        "print(f\"  ‚úÖ Cross-lingual knowledge transfer\")\n",
        "print(f\"  ‚úÖ Larger vocabulary coverage\")\n",
        "print(f\"  ‚úÖ Better generalization capabilities\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Comprehensive Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive evaluation report\n",
        "evaluation_report = generate_evaluation_report(\n",
        "    true_labels=test_results['true_labels'],\n",
        "    predictions=test_results['true_predictions'],\n",
        "    dataset_name=\"Test (XLM-R BERTiƒá)\",\n",
        "    focus_entities=[\"COURT\", \"JUDGE\", \"DEFENDANT\", \"CRIMINAL_ACT\", \"PROVISION\"]\n",
        ")\n",
        "\n",
        "print(\"\\nüåç Multilingual Model Analysis:\")\n",
        "print(\"\\nüî§ Tokenization Comparison:\")\n",
        "sample_text = \"–û—Å–Ω–æ–≤–Ω–∏ —Å—É–¥ —É –ë–µ–æ–≥—Ä–∞–¥—É\"\n",
        "tokens = tokenizer.tokenize(sample_text)\n",
        "print(f\"  Text: '{sample_text}'\")\n",
        "print(f\"  XLM-R tokens: {tokens}\")\n",
        "print(f\"  Token count: {len(tokens)}\")\n",
        "\n",
        "print(\"\\nüéØ Model Strengths:\")\n",
        "print(\"  ‚Ä¢ Cross-lingual pretraining on 100+ languages\")\n",
        "print(\"  ‚Ä¢ Serbian language specialization via BERTiƒá\")\n",
        "print(\"  ‚Ä¢ Robust subword tokenization\")\n",
        "print(\"  ‚Ä¢ Better handling of out-of-vocabulary terms\")\n",
        "print(\"  ‚Ä¢ Improved performance on code-switching scenarios\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Training History and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "plot_training_history(trainer)\n",
        "\n",
        "# Plot entity distribution\n",
        "label_stats = ner_dataset.get_label_statistics()\n",
        "plot_entity_distribution(label_stats['entity_counts'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Inference Pipeline Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load XLM-R BERTiƒá inference pipeline\n",
        "pipeline = load_inference_pipeline(\n",
        "    model_path=OUTPUT_DIR,\n",
        "    max_length=model_config['max_length'],\n",
        "    stride=model_config['stride']\n",
        ")\n",
        "\n",
        "# Test with sample text\n",
        "sample_text = \"\"\"–û—Å–Ω–æ–≤–Ω–∏ —Å—É–¥ —É –ë–µ–æ–≥—Ä–∞–¥—É –¥–æ–Ω–µ–æ —ò–µ –ø—Ä–µ—Å—É–¥—É —É –∫—Ä–∏–≤–∏—á–Ω–æ–º –ø—Ä–µ–¥–º–µ—Ç—É –ö-1234/2023 –ø—Ä–æ—Ç–∏–≤ –æ–ø—Ç—É–∂–µ–Ω–æ–≥ –ú–∞—Ä–∫–∞ –ü–µ—Ç—Ä–æ–≤–∏—õ–∞ –∑–∞ –∫—Ä–∏–≤–∏—á–Ω–æ –¥–µ–ª–æ –∫—Ä–∞—í–µ –∏–∑ —á–ª–∞–Ω–∞ 203 –ö—Ä–∏–≤–∏—á–Ω–æ–≥ –∑–∞–∫–æ–Ω–∏–∫–∞. –°—É–¥–∏—ò–∞ –ê–Ω–∞ –ù–∏–∫–æ–ª–∏—õ –∏–∑—Ä–µ–∫–ª–∞ —ò–µ –∫–∞–∑–Ω—É –∑–∞—Ç–≤–æ—Ä–∞ —É —Ç—Ä–∞—ò–∞—ö—É –æ–¥ 6 –º–µ—Å–µ—Ü–∏.\"\"\"\n",
        "\n",
        "print(\"üîç Testing XLM-R BERTiƒá inference pipeline:\")\n",
        "print(f\"Input text: {sample_text}\")\n",
        "print(\"\\nüìã Detected entities (with XLM-R BERTiƒá):\")\n",
        "\n",
        "entities = pipeline.predict(sample_text)\n",
        "for entity in entities:\n",
        "    print(f\"  {entity['label']}: '{entity['text']}' (tokens {entity['start']}-{entity['end']})\")\n",
        "\n",
        "print(f\"\\n‚úÖ Found {len(entities)} entities using XLM-R BERTiƒá\")\n",
        "print(\"üåç Model benefits from multilingual knowledge and Serbian specialization\")\n",
        "\n",
        "# Test with mixed language content (if applicable)\n",
        "mixed_text = \"–°—É–¥ —ò–µ –¥–æ–Ω–µ–æ decision —É –ø—Ä–µ–¥–º–µ—Ç—É case number –ö-1234/2023.\"\n",
        "print(f\"\\nüîÑ Testing with mixed language text:\")\n",
        "print(f\"Input: {mixed_text}\")\n",
        "mixed_entities = pipeline.predict(mixed_text)\n",
        "print(f\"Entities: {len(mixed_entities)} found\")\n",
        "for entity in mixed_entities:\n",
        "    print(f\"  {entity['label']}: '{entity['text']}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Model Comparison Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nüìä MODEL COMPARISON: BERTiƒá vs XLM-R BERTiƒá\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüá∑üá∏ BERTiƒá (Monolingual):\")\n",
        "print(\"  ‚úÖ Specialized for Serbian language\")\n",
        "print(\"  ‚úÖ Smaller model size\")\n",
        "print(\"  ‚úÖ Faster inference\")\n",
        "print(\"  ‚ùå Limited to Serbian only\")\n",
        "print(\"  ‚ùå No cross-lingual knowledge\")\n",
        "\n",
        "print(\"\\nüåç XLM-R BERTiƒá (Multilingual):\")\n",
        "print(\"  ‚úÖ Cross-lingual knowledge transfer\")\n",
        "print(\"  ‚úÖ Better handling of code-switching\")\n",
        "print(\"  ‚úÖ Robust to language variations\")\n",
        "print(\"  ‚úÖ Larger vocabulary coverage\")\n",
        "print(\"  ‚ùå Larger model size\")\n",
        "print(\"  ‚ùå Potentially slower inference\")\n",
        "\n",
        "print(f\"\\nüéØ Current XLM-R BERTiƒá Performance:\")\n",
        "print(f\"  Precision: {test_results['precision']:.4f}\")\n",
        "print(f\"  Recall: {test_results['recall']:.4f}\")\n",
        "print(f\"  F1-score: {test_results['f1']:.4f}\")\n",
        "print(f\"  Accuracy: {test_results['accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Summary and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nüéØ XLM-R BERTiƒá FINAL SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(f\"Training examples: {len(train_examples)}\")\n",
        "print(f\"Validation examples: {len(val_examples)}\")\n",
        "print(f\"Test examples: {len(test_examples)}\")\n",
        "print(f\"Entity types: {len(ENTITY_TYPES)}\")\n",
        "print(f\"BIO labels: {len(BIO_LABELS)}\")\n",
        "print(f\"\\nModel Configuration:\")\n",
        "print(f\"  Architecture: XLM-RoBERTa + Serbian specialization\")\n",
        "print(f\"  Vocabulary size: {tokenizer.vocab_size:,}\")\n",
        "print(f\"  Max length: {model_config['max_length']}\")\n",
        "print(f\"  Learning rate: {model_config['learning_rate']}\")\n",
        "print(f\"  Epochs: {model_config['num_epochs']}\")\n",
        "print(f\"\\nTest Performance:\")\n",
        "print(f\"  Precision: {test_results['precision']:.4f}\")\n",
        "print(f\"  Recall: {test_results['recall']:.4f}\")\n",
        "print(f\"  F1-score: {test_results['f1']:.4f}\")\n",
        "print(f\"  Accuracy: {test_results['accuracy']:.4f}\")\n",
        "print(f\"\\nModel saved to: {OUTPUT_DIR}\")\n",
        "print(\"\\n‚úÖ XLM-R BERTiƒá pipeline completed successfully!\")\n",
        "print(\"\\nüí° XLM-R BERTiƒá advantages:\")\n",
        "print(\"   ‚Ä¢ Multilingual foundation with Serbian specialization\")\n",
        "print(\"   ‚Ä¢ Cross-lingual knowledge transfer\")\n",
        "print(\"   ‚Ä¢ Better generalization capabilities\")\n",
        "print(\"   ‚Ä¢ Robust handling of language variations\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
