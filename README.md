# Legal NER for Serbian - Montenegro Court Analysis

A complete pipeline for scraping Montenegro court decisions and performing Named Entity Recognition (NER) analysis on Serbian legal texts.

## Project Overview

This project consists of three independent components:

1. **ğŸ•·ï¸ Scraper** - Extracts court decisions from Montenegro court system
2. **ğŸ“ Judgments** - Shared data directory for scraped court decisions
3. **ğŸ§  NER** - Named Entity Recognition analysis of legal texts

## Project Structure

```
legalNer4Serbian/
â”œâ”€â”€ README.md                    # This overview
â”œâ”€â”€ scraper/                     # ğŸ•·ï¸ Court decisions scraper
â”‚   â”œâ”€â”€ montenegro_scraper.py    # Main scraper script
â”‚   â”œâ”€â”€ pyproject.toml          # Scraper dependencies
â”‚   â””â”€â”€ README.md               # Scraper documentation
â”œâ”€â”€ judgments/                   # ğŸ“ Shared data directory
â”‚   â””â”€â”€ judgment_*.txt          # Scraped court decisions
â””â”€â”€ ner/                        # ğŸ§  NER analysis project
    â”œâ”€â”€ pyproject.toml          # NER dependencies
    â”œâ”€â”€ README.md               # NER documentation
    â”œâ”€â”€ notebooks/              # Jupyter notebooks
    â”œâ”€â”€ src/                    # Python modules
    â””â”€â”€ models/                 # Trained models
```

## Quick Start

### 1. Scrape Court Decisions

```bash
cd scraper
uv sync
uv run playwright install
uv run python montenegro_scraper.py
```

This will scrape court decisions and save them to `../judgments/`

### 2. Analyze with NER

```bash
cd ner
uv sync
uv run jupyter lab
```

This will start Jupyter Lab for NER analysis of the scraped judgments.

## Components

### ğŸ•·ï¸ Scraper
- **Purpose**: Extract court decisions from https://sudovi.me/sdvi/odluke
- **Technology**: Pure Playwright (SPA-friendly)
- **Output**: Text files in `../judgments/`
- **Features**: Cookie handling, new window management, batch processing

### ğŸ“ Judgments Directory
- **Purpose**: Shared data storage for court decisions
- **Format**: Plain text files with metadata headers
- **Naming**: `judgment_[case_number].txt`
- **Content**: Court name, case number, date, full judgment text

### ğŸ§  NER Analysis
- **Purpose**: Extract legal entities from judgment texts
- **Technology**: spaCy, Transformers, scikit-learn
- **Input**: Files from `../judgments/`
- **Output**: Extracted entities, trained models, analysis reports

## Dependencies

Each component has its own `pyproject.toml`:
- **Scraper**: Playwright
- **NER**: Jupyter, spaCy, Transformers, pandas, scikit-learn

## Usage Workflow

1. **Scrape** â†’ Run scraper to collect court decisions
2. **Analyze** â†’ Use NER notebooks to extract legal entities
3. **Iterate** â†’ Refine models and scrape more data as needed

## Requirements

- Python 3.12+
- uv package manager